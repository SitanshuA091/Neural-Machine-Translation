{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c81a63",
   "metadata": {},
   "source": [
    "### **NEURAL MACHINE TRANSLATION** \n",
    "- Translating sentence pairs from french to english\n",
    "- Using **Seq2Seq** RNNs and **attention** based sequence models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import unicodedata\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing Functions\n",
    "\n",
    "# Unicode normalization\n",
    "def normalize_unicode(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Preprocess sentences\n",
    "def preprocess_sentence(s):\n",
    "    s = normalize_unicode(s)\n",
    "    s = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", s)\n",
    "    s = re.sub(r'[\" \"]+', \" \", s)\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "# Tag target sentences with <sos> and <eos>\n",
    "def tag_target_sentences(sentences):\n",
    "    tagged_sentences = [' '.join(['<sos>', s, '<eos>']) for s in sentences]\n",
    "    return tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenizer Class\n",
    "class Tokenizer:\n",
    "    def __init__(self, oov_token='<unk>'):\n",
    "        self.word_index = {}\n",
    "        self.index_word = {}\n",
    "        self.oov_token = oov_token\n",
    "        self.oov_index = 1\n",
    "        self.word_index[oov_token] = self.oov_index\n",
    "        self.index_word[self.oov_index] = oov_token\n",
    "        self.next_index = 2\n",
    "    \n",
    "    def fit_on_texts(self, texts):\n",
    "        for text in texts:\n",
    "            words = text.split()\n",
    "            for word in words:\n",
    "                if word not in self.word_index:\n",
    "                    self.word_index[word] = self.next_index\n",
    "                    self.index_word[self.next_index] = word\n",
    "                    self.next_index += 1\n",
    "    \n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            words = text.split()\n",
    "            seq = [self.word_index.get(w, self.oov_index) for w in words]\n",
    "            sequences.append(seq)\n",
    "        return sequences\n",
    "    \n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for seq in sequences:\n",
    "            words = [self.index_word.get(idx, self.oov_token) for idx in seq]\n",
    "            texts.append(' '.join(words))\n",
    "        return texts\n",
    "    \n",
    "    def to_json(self):\n",
    "        return {\n",
    "            'word_index': self.word_index,\n",
    "            'index_word': {int(k): v for k, v in self.index_word.items()},\n",
    "            'oov_token': self.oov_token\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_json(config):\n",
    "        tokenizer = Tokenizer(oov_token=config['oov_token'])\n",
    "        tokenizer.word_index = config['word_index']\n",
    "        tokenizer.index_word = {int(k): v for k, v in config['index_word'].items()}\n",
    "        tokenizer.next_index = max(tokenizer.word_index.values()) + 1\n",
    "        return tokenizer\n",
    "\n",
    "# Pad sequences (PyTorch version)\n",
    "def pad_sequences_pytorch(sequences, max_len, pad_value=0):\n",
    "    padded = np.zeros((len(sequences), max_len), dtype=np.int32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = min(len(seq), max_len)\n",
    "        padded[i, :length] = seq[:length]\n",
    "    return padded\n",
    "\n",
    "def generate_decoder_inputs_targets(sentences, tokenizer):\n",
    "    seqs = tokenizer.texts_to_sequences(sentences)\n",
    "    decoder_inputs = [s[:-1] for s in seqs]\n",
    "    decoder_targets = [s[1:] for s in seqs]\n",
    "    return decoder_inputs, decoder_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e59fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "# Load training data\n",
    "with open('train_sentence_pairs.txt') as file:\n",
    "    train = [line.rstrip() for line in file]\n",
    "\n",
    "print(f\"Training examples: {len(train)}\")\n",
    "print(\"Sample:\", train[:1])\n",
    "\n",
    "# Separate input (French) and target (English)\n",
    "SEPARATOR = '<sep>'\n",
    "train_input, train_target = map(list, zip(*[pair.split(SEPARATOR) for pair in train]))\n",
    "\n",
    "# Preprocess sentences\n",
    "train_preprocessed_input = [preprocess_sentence(s) for s in train_input]\n",
    "train_preprocessed_target = [preprocess_sentence(s) for s in train_target]\n",
    "\n",
    "# Tag target sentences\n",
    "train_tagged_preprocessed_target = tag_target_sentences(train_preprocessed_target)\n",
    "\n",
    "# Create tokenizers\n",
    "source_tokenizer = Tokenizer(oov_token='<unk>')\n",
    "source_tokenizer.fit_on_texts(train_preprocessed_input)\n",
    "source_vocab_size = len(source_tokenizer.word_index) + 1\n",
    "\n",
    "target_tokenizer = Tokenizer(oov_token='<unk>')\n",
    "target_tokenizer.fit_on_texts(train_tagged_preprocessed_target)\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "print(f\"Source vocab size: {source_vocab_size}\")\n",
    "print(f\"Target vocab size: {target_vocab_size}\")\n",
    "\n",
    "# Vectorize sequences\n",
    "train_encoder_inputs = source_tokenizer.texts_to_sequences(train_preprocessed_input)\n",
    "train_decoder_inputs, train_decoder_targets = generate_decoder_inputs_targets(\n",
    "    train_tagged_preprocessed_target, target_tokenizer)\n",
    "\n",
    "# Pad sequences\n",
    "max_encoding_len = len(max(train_encoder_inputs, key=len))\n",
    "max_decoding_len = len(max(train_decoder_inputs, key=len))\n",
    "\n",
    "padded_train_encoder_inputs = pad_sequences_pytorch(train_encoder_inputs, max_encoding_len)\n",
    "padded_train_decoder_inputs = pad_sequences_pytorch(train_decoder_inputs, max_decoding_len)\n",
    "padded_train_decoder_targets = pad_sequences_pytorch(train_decoder_targets, max_decoding_len)\n",
    "\n",
    "print(f\"Max encoding length: {max_encoding_len}\")\n",
    "print(f\"Max decoding length: {max_decoding_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb532a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validation Data Processing\n",
    "\n",
    "# Load validation data\n",
    "with open('val_sentence_pairs.txt') as file:\n",
    "    val = [line.rstrip() for line in file]\n",
    "\n",
    "def process_dataset(dataset):\n",
    "    input_data, output_data = map(list, zip(*[pair.split(SEPARATOR) for pair in dataset]))\n",
    "    preprocessed_input = [preprocess_sentence(s) for s in input_data]\n",
    "    preprocessed_output = [preprocess_sentence(s) for s in output_data]\n",
    "    tagged_preprocessed_output = tag_target_sentences(preprocessed_output)\n",
    "    \n",
    "    encoder_inputs = source_tokenizer.texts_to_sequences(preprocessed_input)\n",
    "    decoder_inputs, decoder_targets = generate_decoder_inputs_targets(\n",
    "        tagged_preprocessed_output, target_tokenizer)\n",
    "    \n",
    "    padded_encoder_inputs = pad_sequences_pytorch(encoder_inputs, max_encoding_len)\n",
    "    padded_decoder_inputs = pad_sequences_pytorch(decoder_inputs, max_decoding_len)\n",
    "    padded_decoder_targets = pad_sequences_pytorch(decoder_targets, max_decoding_len)\n",
    "    \n",
    "    return padded_encoder_inputs, padded_decoder_inputs, padded_decoder_targets\n",
    "\n",
    "padded_val_encoder_inputs, padded_val_decoder_inputs, padded_val_decoder_targets = process_dataset(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcdd961",
   "metadata": {},
   "source": [
    "**RECCURENCE BASED Seq2Seq MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PyTorch Models - No Attention\n",
    "\n",
    "class EncoderNoAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout=0.2):\n",
    "        super(EncoderNoAttention, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "class DecoderNoAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout=0.2):\n",
    "        super(DecoderNoAttention, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
    "        self.dense = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden, cell):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        logits = self.dense(outputs)\n",
    "        return logits, hidden, cell\n",
    "\n",
    "class Seq2SeqNoAttention(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2SeqNoAttention, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "        logits, _, _ = self.decoder(tgt, hidden, cell)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109059c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PyTorch Models - With Luong Attention\n",
    "\n",
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.w = nn.Linear(hidden_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, encoder_outputs, decoder_output):\n",
    "        # encoder_outputs: (batch, seq_len, hidden_dim)\n",
    "        # decoder_output: (batch, 1, hidden_dim)\n",
    "        z = self.w(encoder_outputs)  # (batch, seq_len, hidden_dim)\n",
    "        scores = torch.bmm(decoder_output, z.transpose(1, 2))  # (batch, 1, seq_len)\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, encoder_outputs)  # (batch, 1, hidden_dim)\n",
    "        return weights, context\n",
    "\n",
    "class EncoderWithAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout=0.2):\n",
    "        super(EncoderWithAttention, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout, return_sequences=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "class DecoderWithAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout=0.2):\n",
    "        super(DecoderWithAttention, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
    "        self.attention = LuongAttention(hidden_dim)\n",
    "        self.w_attention = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.w_attention.activation = nn.Tanh()\n",
    "        self.dense = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x, encoder_outputs, hidden, cell):\n",
    "        embedded = self.embedding(x)\n",
    "        decoder_output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        weights, context = self.attention(encoder_outputs, decoder_output)\n",
    "        combined = torch.cat([context, decoder_output], dim=-1)\n",
    "        attended = torch.tanh(self.w_attention(combined))\n",
    "        logits = self.dense(attended)\n",
    "        return logits, hidden, cell, weights\n",
    "\n",
    "class Seq2SeqWithAttention(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2SeqWithAttention, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src, tgt, encoder_outputs):\n",
    "        decoder_logits_list = []\n",
    "        hidden, cell = None, None\n",
    "        \n",
    "        for t in range(tgt.size(1)):\n",
    "            decoder_input = tgt[:, t:t+1]\n",
    "            logits, hidden, cell, _ = self.decoder(decoder_input, encoder_outputs, hidden, cell)\n",
    "            decoder_logits_list.append(logits)\n",
    "        \n",
    "        return torch.cat(decoder_logits_list, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc984f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Setup\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "dropout = 0.2\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Convert to tensors\n",
    "train_encoder_tensor = torch.LongTensor(padded_train_encoder_inputs)\n",
    "train_decoder_input_tensor = torch.LongTensor(padded_train_decoder_inputs)\n",
    "train_decoder_target_tensor = torch.LongTensor(padded_train_decoder_targets)\n",
    "\n",
    "val_encoder_tensor = torch.LongTensor(padded_val_encoder_inputs)\n",
    "val_decoder_input_tensor = torch.LongTensor(padded_val_decoder_inputs)\n",
    "val_decoder_target_tensor = torch.LongTensor(padded_val_decoder_targets)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(train_encoder_tensor, train_decoder_input_tensor, train_decoder_target_tensor)\n",
    "val_dataset = TensorDataset(val_encoder_tensor, val_decoder_input_tensor, val_decoder_target_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Custom loss function with masking\n",
    "class MaskedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedCrossEntropyLoss, self).__init__()\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        # logits: (batch, seq_len, vocab_size)\n",
    "        # targets: (batch, seq_len)\n",
    "        batch_size, seq_len, vocab_size = logits.size()\n",
    "        \n",
    "        logits_flat = logits.reshape(-1, vocab_size)\n",
    "        targets_flat = targets.reshape(-1)\n",
    "        \n",
    "        loss = self.ce_loss(logits_flat, targets_flat)\n",
    "        mask = (targets_flat != 0).float()\n",
    "        masked_loss = (loss * mask).sum() / (mask.sum() + 1e-8)\n",
    "        \n",
    "        return masked_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e1203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Function - No Attention\n",
    "\n",
    "def train_no_attention(epochs):\n",
    "    encoder = EncoderNoAttention(source_vocab_size, embedding_dim, hidden_dim, dropout).to(device)\n",
    "    decoder = DecoderNoAttention(target_vocab_size, embedding_dim, hidden_dim, dropout).to(device)\n",
    "    model = Seq2SeqNoAttention(encoder, decoder).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = MaskedCrossEntropyLoss()\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for enc_input, dec_input, dec_target in train_loader:\n",
    "            enc_input = enc_input.to(device)\n",
    "            dec_input = dec_input.to(device)\n",
    "            dec_target = dec_target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(enc_input, dec_input)\n",
    "            loss = criterion(logits, dec_target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for enc_input, dec_input, dec_target in val_loader:\n",
    "                enc_input = enc_input.to(device)\n",
    "                dec_input = dec_input.to(device)\n",
    "                dec_target = dec_target.to(device)\n",
    "                \n",
    "                logits = model(enc_input, dec_input)\n",
    "                loss = criterion(logits, dec_target)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b538b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Function - With Attention\n",
    "\n",
    "def train_with_attention(epochs):\n",
    "    encoder = EncoderWithAttention(source_vocab_size, embedding_dim, hidden_dim, dropout).to(device)\n",
    "    decoder = DecoderWithAttention(target_vocab_size, embedding_dim, hidden_dim, dropout).to(device)\n",
    "    model = Seq2SeqWithAttention(encoder, decoder).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = MaskedCrossEntropyLoss()\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for enc_input, dec_input, dec_target in train_loader:\n",
    "            enc_input = enc_input.to(device)\n",
    "            dec_input = dec_input.to(device)\n",
    "            dec_target = dec_target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            encoder_outputs, _, _ = model.encoder(enc_input)\n",
    "            logits = model(enc_input, dec_input, encoder_outputs)\n",
    "            loss = criterion(logits, dec_target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for enc_input, dec_input, dec_target in val_loader:\n",
    "                enc_input = enc_input.to(device)\n",
    "                dec_input = dec_input.to(device)\n",
    "                dec_target = dec_target.to(device)\n",
    "                \n",
    "                encoder_outputs, _, _ = model.encoder(enc_input)\n",
    "                logits = model(enc_input, dec_input, encoder_outputs)\n",
    "                loss = criterion(logits, dec_target)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f211562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Execution (Uncomment traininge ke time krna hai)\n",
    "\n",
    "# print(\"Training model without attention...\")\n",
    "# model_no_attn, train_losses_no_attn, val_losses_no_attn = train_no_attention(epochs)\n",
    "\n",
    "# print(\"Training model with attention...\")\n",
    "# model_attn, train_losses_attn, val_losses_attn = train_with_attention(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4471810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference Functions\n",
    "\n",
    "def translate_no_attention(sentence, encoder, decoder, source_tokenizer, target_tokenizer, max_len=30):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    input_seq = source_tokenizer.texts_to_sequences([sentence])\n",
    "    input_padded = torch.LongTensor(pad_sequences_pytorch(input_seq, max_encoding_len)).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, hidden, cell = encoder(input_padded)\n",
    "    \n",
    "    decoded = []\n",
    "    current_token = '<sos>'\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        token_idx = target_tokenizer.word_index.get(current_token, 1)\n",
    "        decoder_input = torch.LongTensor([[token_idx]]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits, hidden, cell = decoder(decoder_input, hidden, cell)\n",
    "        \n",
    "        token_idx = torch.argmax(logits[0, -1, :]).item()\n",
    "        current_token = target_tokenizer.index_word.get(token_idx, '<unk>')\n",
    "        \n",
    "        if current_token == '<eos>':\n",
    "            break\n",
    "        \n",
    "        decoded.append(current_token)\n",
    "    \n",
    "    return ' '.join(decoded)\n",
    "\n",
    "def translate_with_attention(sentence, encoder, decoder, source_tokenizer, target_tokenizer, max_len=30):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    input_seq = source_tokenizer.texts_to_sequences([sentence])\n",
    "    input_padded = torch.LongTensor(pad_sequences_pytorch(input_seq, max_encoding_len)).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden, cell = encoder(input_padded)\n",
    "    \n",
    "    decoded = []\n",
    "    current_token = '<sos>'\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        token_idx = target_tokenizer.word_index.get(current_token, 1)\n",
    "        decoder_input = torch.LongTensor([[token_idx]]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits, hidden, cell, _ = decoder(decoder_input, encoder_outputs, hidden, cell)\n",
    "        \n",
    "        token_idx = torch.argmax(logits[0, -1, :]).item()\n",
    "        current_token = target_tokenizer.index_word.get(token_idx, '<unk>')\n",
    "        \n",
    "        if current_token == '<eos>':\n",
    "            break\n",
    "        \n",
    "        decoded.append(current_token)\n",
    "    \n",
    "    return ' '.join(decoded)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
